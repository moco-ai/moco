"""
FastAPI backend for Moco Web UI
ChatGPT-like interface
"""
import os
import re
import asyncio
import queue
import threading
import time
import sys
from typing import Optional

# moco imports - sys.path must be set before importing moco modules
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, StreamingResponse
from pydantic import BaseModel
from moco.common.schemas import ChatRequest, SessionCreate, FileResponse
from moco.common.errors import setup_exception_handlers
import json
import sqlite3
import logging
from datetime import datetime, date
from dotenv import load_dotenv, find_dotenv

# .env ã‚’èª­ã¿è¾¼ã‚€ï¼ˆè¦ªæ–¹å‘ã«è‡ªå‹•æ¢ç´¢ï¼‰
load_dotenv(find_dotenv())

from moco.core.orchestrator import Orchestrator
from moco.storage.session_logger import SessionLogger
from moco.tools.discovery import _find_profiles_dir
from moco.utils.json_parser import SmartJSONParser
from moco.cancellation import (
    create_cancel_event,
    request_cancel,
    clear_cancel_event,
    OperationCancelled
)


def filter_response_for_display(response: str, verbose: bool = False) -> str:
    """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆverboseã§ãªã„å ´åˆã¯æœ€å¾Œã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã ã‘ï¼‰"""
    if not response:
        return ""
    if verbose:
        return response

    # @agent: å¿œç­” ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§åˆ†å‰²
    sections = re.split(r'(@[\w-]+):\s*', response)

    if len(sections) > 1:
        # æœ€å¾Œã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœã ã‘ã‚’å–å¾—
        last_agent = sections[-2] if len(sections) >= 2 else ""
        last_content = sections[-1].strip() if sections[-1] else ""

        # orchestrator ã®æœ€çµ‚å›ç­”ã¯çœç•¥ã—ãªã„
        if last_agent == "@orchestrator":
            return last_content
        else:
            # ä¸­é–“ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å ´åˆã‚‚å…¨æ–‡è¿”ã™ï¼ˆUIã§ã®è¡¨ç¤ºã¯åˆ¥é€”å¯¾å¿œï¼‰
            return f"{last_agent}: {last_content}"

    return response

app = FastAPI(title="Moco", version="1.0.0")
setup_exception_handlers(app)

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚¦ãƒ³ãƒˆ
static_dir = os.path.join(os.path.dirname(__file__), "static")
app.mount("/static", StaticFiles(directory=static_dir), name="static")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹
session_logger = SessionLogger()
logger = logging.getLogger(__name__)


def get_orchestrator(profile: str, provider: str = "gemini", verbose: bool = False, working_directory: str = None) -> Orchestrator:
    """Orchestratorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ–°è¦ç”Ÿæˆ"""
    # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: å¼•æ•° > ç’°å¢ƒå¤‰æ•° > ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    work_dir = working_directory or os.getenv("MOCO_WORKING_DIRECTORY") or os.getcwd()
    return Orchestrator(
        profile=profile,
        provider=provider,
        session_logger=session_logger,
        verbose=verbose,
        working_directory=work_dir
    )



# === Routes ===

@app.get("/", response_class=HTMLResponse)
async def root():
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸"""
    with open(os.path.join(static_dir, "index.html"), "r") as f:
        return f.read()


@app.get("/api/browse-directories")
async def browse_directories(path: str = None):
    """
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§ã‚’å–å¾—ï¼ˆãƒ•ã‚©ãƒ«ãƒ€é¸æŠUIç”¨ï¼‰
    path ãŒ None ã®å ´åˆã¯ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’èµ·ç‚¹ã¨ã™ã‚‹
    """
    # ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ±ºå®š
    # realpath ã‚’ä½¿ç”¨ã—ã¦ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’è§£æ±º
    base_dir = os.path.realpath(os.getenv("MOCO_WORKING_DIRECTORY") or os.getcwd())

    if path is None:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        base_paths = [
            {"path": base_dir, "name": "Workspace", "icon": "ğŸ "},
        ]
        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚ã‚Œã°è¿½åŠ 
        for sub in ["src", "profiles", "workspace"]:
            full = os.path.join(base_dir, sub)
            if os.path.isdir(full):
                base_paths.append({"path": full, "name": sub, "icon": "ğŸ“"})
        
        return {"directories": base_paths, "current": base_dir}

    # ãƒ‘ã‚¹ã®æ­£è¦åŒ–ã¨æ¤œè¨¼
    try:
        requested_path = os.path.normpath(path)
        if os.path.isabs(requested_path):
            target_path = os.path.realpath(requested_path)
        else:
            target_path = os.path.realpath(os.path.join(base_dir, requested_path))

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–: target_path ãŒ base_dir ã®é…ä¸‹ã«ã‚ã‚‹ã‹ç¢ºèª
        if os.path.commonpath([base_dir, target_path]) != base_dir:
            return {
                "error": f"Access denied: {path} is outside the working directory",
                "directories": [],
                "current": path
            }
    except ValueError:
        # Windowsã®ãƒ‰ãƒ©ã‚¤ãƒ–è·¨ããªã©ã®å ´åˆã«ç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
        return {
            "error": f"Invalid path access: {path}",
            "directories": [],
            "current": path
        }

    if not os.path.exists(target_path):
        return {"error": f"Path not found: {path}", "directories": [], "current": path}

    if not os.path.isdir(target_path):
        return {"error": f"Not a directory: {path}", "directories": [], "current": path}

    try:
        items = os.listdir(target_path)
        directories = []
        for item in sorted(items):
            if item.startswith('.'):
                continue  # éš ã—ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—
            full_item_path = os.path.join(target_path, item)
            if os.path.isdir(full_item_path):
                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‹ã©ã†ã‹ã‚’åˆ¤å®š
                is_project = any(
                    os.path.exists(os.path.join(full_item_path, marker))
                    for marker in [".git", "package.json", "pyproject.toml", "requirements.txt"]
                )
                directories.append({
                    "path": full_item_path,
                    "name": item,
                    "icon": "ğŸ“¦" if is_project else "ğŸ“",
                    "is_project": is_project
                })

        parent = os.path.dirname(target_path)
        # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚åˆ¶é™å†…ã§ã‚ã‚‹å ´åˆã®ã¿è¿”ã™
        try:
            if os.path.commonpath([base_dir, parent]) != base_dir:
                parent = None
        except ValueError:
            parent = None

        return {
            "directories": directories,
            "current": target_path,
            "parent": parent if parent != target_path else None
        }
    except Exception as e:
        logger.exception(f"Error browsing directory: {target_path}")
        return {"error": str(e), "directories": [], "current": target_path}


@app.get("/api/profiles")
async def list_profiles():
    """åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§"""
    profiles_dir = _find_profiles_dir()
    if not os.path.exists(profiles_dir):
        return {"profiles": ["default"]}

    profiles = [
        d for d in os.listdir(profiles_dir)
        if os.path.isdir(os.path.join(profiles_dir, d)) and d != "__pycache__"
    ]
    return {"profiles": sorted(profiles)}


@app.get("/api/sessions")
async def list_sessions(limit: int = 20, profile: str = None):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸€è¦§ï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ•ã‚£ãƒ«ã‚¿å¯èƒ½ï¼‰"""
    sessions = session_logger.list_sessions(limit=limit, profile=profile)
    return {"sessions": sessions}


@app.post("/api/sessions")
async def create_session(req: SessionCreate):
    """æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ"""
    orchestrator = get_orchestrator(req.profile)
    session_id = orchestrator.create_session(title=req.title, profile=req.profile)
    return {"session_id": session_id, "title": req.title}


@app.post("/api/sessions/{session_id}/cancel")
async def cancel_task(session_id: str):
    """å®Ÿè¡Œä¸­ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
    success = request_cancel(session_id)
    return {"status": "success" if success else "not_found", "session_id": session_id}


@app.get("/api/sessions/{session_id}")
async def get_session(session_id: str):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³è©³ç´°ã¨å±¥æ­´"""
    session = session_logger.get_session(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")

    history = session_logger._get_recent_messages(session_id, limit=100)
    return {
        "session": session,
        "messages": history
    }


@app.get("/api/file", response_model=FileResponse)
async def get_file_content(path: str):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã€‚
    ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–ã‚’æ–½ã—ã€MOCO_WORKING_DIRECTORYé…ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã€‚
    """
    # ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ±ºå®š
    base_dir = os.path.abspath(os.getenv("MOCO_WORKING_DIRECTORY") or os.getcwd())

    # ãƒ‘ã‚¹ã®æ­£è¦åŒ–ã¨æ¤œè¨¼
    requested_path = os.path.normpath(path)
    if os.path.isabs(requested_path):
        # çµ¶å¯¾ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯ã€ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã¨ã—ã¦æ‰±ã†
        requested_path = requested_path.lstrip(os.sep)

    target_path = os.path.abspath(os.path.join(base_dir, requested_path))

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–: target_path ãŒ base_dir ã®é…ä¸‹ã«ã‚ã‚‹ã‹ç¢ºèª
    if os.path.commonpath([base_dir, target_path]) != base_dir:
        raise HTTPException(
            status_code=403,
            detail=f"Access denied: {path} is outside the working directory"
        )

    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(target_path):
        raise HTTPException(status_code=404, detail=f"File not found: {path}")

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ãªã„ã“ã¨ã‚’ç¢ºèª
    if not os.path.isfile(target_path):
        raise HTTPException(status_code=400, detail=f"Path is not a file: {path}")

    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®å–å¾—
        size = os.path.getsize(target_path)

        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦èª­ã¿è¾¼ã¿
        with open(target_path, 'r', encoding='utf-8') as f:
            content = f.read()

        line_count = len(content.splitlines())

        return FileResponse(
            content=content,
            line_count=line_count,
            size=size,
            path=path
        )
    except UnicodeDecodeError:
        raise HTTPException(
            status_code=400,
            detail="File is not a valid UTF-8 text file"
        )
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error reading file: {str(e)}"
        )


@app.delete("/api/sessions/{session_id}")
async def delete_session(session_id: str):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³å‰Šé™¤"""
    try:
        session_logger.delete_session(session_id)
        return {"status": "ok"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/stats")
async def get_stats(session_id: Optional[str] = None, scope: str = "all"):
    """çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        from pathlib import Path
        db_path = Path(__file__).parent.parent.parent.parent / "data" / "optimizer" / "metrics.db"
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ 
        stats = {
            "today_avg_score": 0,
            "today_count": 0,
            "avg_score": 0,
            "count": 0,
            "success_rate": 0,
            "overall_metrics": {
                "avg_complexity": 0,
                "avg_delegation": 0,
                "todo_usage_rate": 0,
                "avg_history_turns": 0,
                "avg_summary_depth": 0,
                "avg_prompt_specificity": 0,
                "summaries": 0
            },
            "profile_stats": [],
            "recent_tasks": [],
            "score_trend": [],
            "agent_stats": {}
        }

        if scope == "session" and not session_id:
            return stats

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆã¨åˆæœŸåŒ–
        db_path.parent.mkdir(parents=True, exist_ok=True)
        if not db_path.exists():
            # æ–°è¦ä½œæˆæ™‚ã¯ç©ºã®çµ±è¨ˆã‚’è¿”ã™ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆå¾Œã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„çŠ¶æ…‹ã¨åŒã˜ï¼‰
            conn = sqlite3.connect(str(db_path))
            # ã“ã“ã§ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            cursor = conn.cursor()
            cursor.execute("CREATE TABLE IF NOT EXISTS metrics (id INTEGER PRIMARY KEY AUTOINCREMENT, session_id TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP, ai_score REAL, task_summary TEXT, task_complexity REAL, delegation_count INTEGER, todo_used INTEGER, history_turns INTEGER, summary_depth INTEGER, prompt_specificity REAL, profile TEXT)")
            cursor.execute("CREATE TABLE IF NOT EXISTS agent_executions (id INTEGER PRIMARY KEY AUTOINCREMENT, request_id INTEGER, agent_name TEXT, inline_score REAL, tokens_input INTEGER, tokens_output INTEGER, execution_time_ms INTEGER, error_message TEXT, summary_depth INTEGER, history_turns INTEGER, FOREIGN KEY (request_id) REFERENCES metrics (id))")
            conn.commit()
            return stats
        
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()

        # ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã®æ§‹ç¯‰ (metricsãƒ†ãƒ¼ãƒ–ãƒ«)
        where_clause = "WHERE ai_score IS NOT NULL"
        params = []

        if scope == "session" and session_id:
            where_clause += " AND session_id = ?"
            params.append(session_id)
        elif scope == "today":
            where_clause += " AND timestamp >= date('now', 'localtime')"
        # "all" ã®å ´åˆã¯è¿½åŠ æ¡ä»¶ãªã—

        # ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã®æ§‹ç¯‰ (agent_executionsãƒ†ãƒ¼ãƒ–ãƒ«)
        # agent_executionsã«ã¯session_idã‚„timestampãŒãªã„ãŸã‚ã€metricsã¨JOINãŒå¿…è¦ãªå ´åˆãŒã‚ã‚‹
        ae_join = ""
        where_clause_ae = "WHERE 1=1"
        params_ae = []
        if scope == "session" and session_id:
            ae_join = "JOIN metrics m ON agent_executions.request_id = m.id"
            where_clause_ae = "WHERE m.session_id = ?"
            params_ae.append(session_id)
        elif scope == "today":
            ae_join = "JOIN metrics m ON agent_executions.request_id = m.id"
            where_clause_ae = "WHERE m.timestamp >= date('now', 'localtime')"

        # ä»Šæ—¥ã®çµ±è¨ˆ
        cursor.execute(f"""
            SELECT AVG(ai_score), COUNT(*),
                   SUM(CASE WHEN ai_score >= 0.7 THEN 1 ELSE 0 END) * 1.0 / COUNT(*)
            FROM metrics
            {where_clause}
        """, params)
        row = cursor.fetchone()
        today_avg = row[0] or 0
        today_count = row[1] or 0
        success_rate = row[2] or 0

        # å…¨ä½“ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        cursor.execute(f"""
            SELECT
                AVG(task_complexity),
                AVG(delegation_count),
                AVG(CASE WHEN todo_used = 1 THEN 1.0 ELSE 0 END) * 100,
                AVG(history_turns),
                AVG(summary_depth),
                AVG(prompt_specificity),
                SUM(CASE WHEN summary_depth > 0 THEN 1 ELSE 0 END)
            FROM metrics
            {where_clause}
        """, params)
        metrics_row = cursor.fetchone()
        overall_metrics = {
            "avg_complexity": round(metrics_row[0] or 0, 1),
            "avg_delegation": round(metrics_row[1] or 0, 1),
            "todo_usage_rate": round(metrics_row[2] or 0, 1),
            "avg_history_turns": round(metrics_row[3] or 0, 1),
            "avg_summary_depth": round(metrics_row[4] or 0, 1),
            "avg_prompt_specificity": round(metrics_row[5] or 0, 1),
            "summaries": metrics_row[6] or 0
        }

        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥çµ±è¨ˆ
        cursor.execute(f"""
            SELECT profile, AVG(ai_score), COUNT(*)
            FROM metrics
            {where_clause}
            GROUP BY profile
            ORDER BY COUNT(*) DESC
            LIMIT 5
        """, params)
        profile_stats = [
            {"profile": r[0], "avg_score": r[1] or 0, "count": r[2]}
            for r in cursor.fetchall()
        ]

        # æœ€æ–°ã‚¿ã‚¹ã‚¯
        cursor.execute(f"""
            SELECT task_summary, ai_score, task_complexity, timestamp
            FROM metrics
            {where_clause}
            ORDER BY id DESC
            LIMIT 5
        """, params)
        recent_tasks = [
            {
                "task": r[0][:40] + "..." if r[0] and len(r[0]) > 40 else (r[0] or ""),
                "score": r[1] or 0,
                "complexity": r[2] or 0,
                "time": r[3].split("T")[1][:5] if r[3] and "T" in r[3] else ""
            }
            for r in cursor.fetchall()
        ]

        # ã‚¹ã‚³ã‚¢æ¨ç§»ï¼ˆç›´è¿‘10ä»¶ï¼‰
        cursor.execute(f"""
            SELECT ai_score FROM metrics
            {where_clause}
            ORDER BY id DESC
            LIMIT 10
        """, params)
        score_trend = [r[0] for r in cursor.fetchall()][::-1]

        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¥çµ±è¨ˆï¼ˆæ–°ãƒ†ãƒ¼ãƒ–ãƒ«å„ªå…ˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚ã‚Šï¼‰
        agent_stats = {}

        # æ–°ã—ã„ agent_executions ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        try:
            cursor.execute(f"""
                SELECT
                    agent_name,
                    COUNT(*) as total,
                    AVG(inline_score) as avg_score,
                    AVG(tokens_input + tokens_output) as avg_tokens,
                    AVG(execution_time_ms) as avg_time_ms,
                    SUM(CASE WHEN inline_score >= 0.7 THEN 1 ELSE 0 END) as success_count,
                    SUM(CASE WHEN error_message IS NOT NULL THEN 1 ELSE 0 END) as error_count,
                    AVG(agent_executions.summary_depth),
                    AVG(agent_executions.history_turns),
                    SUM(CASE WHEN agent_executions.summary_depth > 0 THEN 1 ELSE 0 END) as summaries
                FROM agent_executions
                {ae_join}
                {where_clause_ae}
                GROUP BY agent_name
                ORDER BY total DESC
                LIMIT 10
            """, params_ae)
            rows = cursor.fetchall()

            if rows:
                for row in rows:
                    agent_name = row[0]
                    total = row[1]
                    agent_stats[agent_name] = {
                        "total": total,
                        "success": row[5] or 0,
                        "avg_score": round(row[2] or 0, 2),
                        "avg_tokens": round(row[3] or 0),
                        "avg_time_ms": round(row[4] or 0),
                        "success_rate": round((row[5] / total * 100) if total > 0 else 0, 1),
                        "error_rate": round((row[6] / total * 100) if total > 0 else 0, 1),
                        "avg_summary_depth": round(row[7] or 0, 1),
                        "avg_history_turns": round(row[8] or 0, 1),
                        "summaries": row[9] or 0
                    }
        except sqlite3.OperationalError:
            pass  # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒã¾ã å­˜åœ¨ã—ãªã„å ´åˆ

        # æ–°ãƒ†ãƒ¼ãƒ–ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯æ—§æ–¹å¼ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not agent_stats:
            cursor.execute(f"""
                SELECT agents_selected, ai_score, task_complexity, delegation_count, todo_used
                FROM metrics
                {where_clause} AND agents_selected IS NOT NULL
            """, params)
            rows = cursor.fetchall()

            from collections import defaultdict
            agent_counts = defaultdict(int)
            agent_scores = defaultdict(float)
            agent_success = defaultdict(int)
            agent_complexity = defaultdict(float)
            agent_delegation = defaultdict(float)
            agent_todo = defaultdict(int)

            for agents_json, score, complexity, delegation, todo in rows:
                try:
                    agents = json.loads(agents_json)
                    if isinstance(agents, list):
                        for agent in agents:
                            agent_counts[agent] += 1
                            agent_scores[agent] += score
                            if score >= 0.7:
                                agent_success[agent] += 1
                            agent_complexity[agent] += (complexity or 0)
                            agent_delegation[agent] += (delegation or 0)
                            if todo:
                                agent_todo[agent] += 1
                except Exception:
                    continue

            for agent, count in agent_counts.items():
                avg_score = agent_scores[agent] / count
                agent_stats[agent] = {
                    "total": count,
                    "success": agent_success[agent],
                    "avg_score": round(avg_score, 2),
                    "avg_complexity": round(agent_complexity[agent] / count, 1),
                    "avg_delegation": round(agent_delegation[agent] / count, 1),
                    "todo_usage": round(agent_todo[agent] / count * 100, 1),
                    "summaries": 0,
                    "avg_history_turns": 0
                }

            # ä¸Šä½10ä»¶ã«çµã‚‹ï¼ˆcountã®å¤šã„é †ï¼‰
            sorted_agents = sorted(agent_stats.items(), key=lambda x: x[1]["total"], reverse=True)[:10]
            agent_stats = dict(sorted_agents)

        conn.close()
        
        return {
            "today_avg_score": round(today_avg, 2),
            "today_count": today_count,
            "avg_score": round(today_avg, 2),
            "count": today_count,
            "success_rate": round(success_rate * 100, 1),
            "overall_metrics": overall_metrics,
            "profile_stats": profile_stats,
            "recent_tasks": recent_tasks,
            "score_trend": score_trend,
            "agent_stats": agent_stats
        }
    except Exception as e:
        return {"error": str(e)}


@app.post("/api/chat")
async def chat(req: ChatRequest):
    """ãƒãƒ£ãƒƒãƒˆï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰"""
    orchestrator = get_orchestrator(
        req.profile,
        req.provider,
        req.verbose,
        req.working_directory
    )

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
    session_id = req.session_id
    if not session_id:
        session_id = orchestrator.create_session(title=req.message[:50])

    # å®Ÿè¡Œ
    response = orchestrator.run_sync(req.message, session_id=session_id)

    return {
        "response": response,
        "session_id": session_id
    }


@app.post("/api/chat/stream")
async def chat_stream(req: ChatRequest):
    """ãƒãƒ£ãƒƒãƒˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰- Server-Sent Events with real-time tool updates"""

    # ã‚¤ãƒ™ãƒ³ãƒˆã‚­ãƒ¥ãƒ¼ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰é–“é€šä¿¡ç”¨ï¼‰
    event_queue = queue.Queue()

    # thinking ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒãƒƒãƒåŒ–ç”¨
    thinking_buffer = ""
    last_thinking_time = 0
    last_agent_name = "orchestrator"

    # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    def progress_callback(event_type: str, name: str = None, detail: str = "", agent_name: str = None, parent_agent: str = None, status: str = "running", tool_name: str = None, content: str = None, result: str = None, **kwargs):
        nonlocal thinking_buffer, last_thinking_time, last_agent_name
        
        current_agent = agent_name or last_agent_name or "orchestrator"
        last_agent_name = current_agent

        if event_type == "thinking":
            thinking_buffer += (content or "")
            current_time = time.time()
            # 100æ–‡å­—ä»¥ä¸Šã€ã¾ãŸã¯0.2ç§’çµŒéã—ãŸã‚‰é€ä¿¡
            if len(thinking_buffer) >= 100 or (current_time - last_thinking_time) >= 0.2:
                event_queue.put({
                    "type": "thinking",
                    "content": thinking_buffer,
                    "agent": current_agent
                })
                thinking_buffer = ""
                last_thinking_time = current_time
            return

        # æ€è€ƒä»¥å¤–ã®ã‚¤ãƒ™ãƒ³ãƒˆãŒç™ºç”Ÿã—ãŸå ´åˆã¯ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆé †åºç¶­æŒï¼‰
        if thinking_buffer:
            event_queue.put({
                "type": "thinking",
                "content": thinking_buffer,
                "agent": current_agent
            })
            thinking_buffer = ""
            
        if event_type == "flush":
            return

        if event_type == "chunk":
            event_queue.put({
                "type": "chunk",
                "content": content,
                "agent": current_agent
            })
            return

        # agent_name ãŒæ˜ç¤ºçš„ã« None ã®å ´åˆã‚’ã‚¬ãƒ¼ãƒ‰
        agent_name = agent_name or "orchestrator"
        
        # åå‰ãŒæä¾›ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåã‚’ä½¿ç”¨ï¼ˆrecallãªã©ã®å ´åˆï¼‰
        display_name = name or agent_name or ""
        # ã‚¢ã‚¤ã‚³ãƒ³ã‚’å‰Šé™¤ã—ã¦ãƒ„ãƒ¼ãƒ«å/ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåã®ã¿ã«ã™ã‚‹
        clean_name = display_name
        if display_name and " " in display_name:
            parts = display_name.split()
            if parts:
                clean_name = parts[-1]

        # ã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒ‘ãƒãƒ«ç”¨ã®ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡
        if event_type == "recall":
            results = kwargs.get("results", [])
            for res in results:
                event_queue.put({
                    "type": "recall",
                    "recall_type": "Memory",
                    "query": detail or "Semantic Recall",
                    "details": res.get("content", "") if isinstance(res, dict) else str(res)
                })
        elif event_type == "delegate" and status == "running":
            event_queue.put({
                "type": "recall",
                "recall_type": "Delegation",
                "query": f"â†’ @{clean_name}",
                "details": detail
            })
        elif event_type == "tool" and status == "completed":
            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã‚‚ã‚¤ãƒ³ã‚µã‚¤ãƒˆã«è¡¨ç¤º
            event_queue.put({
                "type": "recall",
                "recall_type": "Tool",
                "query": f"ğŸ› ï¸ {tool_name or clean_name}",
                "details": result
            })

        # app.js ãŒæœŸå¾…ã™ã‚‹å½¢å¼ï¼ˆagent, parent, tool, event, statusï¼‰ã«çµ±ä¸€
        data = {
            "type": "progress",
            "agent": agent_name,
            "parent": parent_agent,
            "tool": tool_name or (clean_name if event_type == "tool" else None),
            "event": event_type,
            "status": status,
            "name": clean_name,
            "detail": detail
        }
        event_queue.put(data)

    # Orchestrator ã‚’ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ãã§ä½œæˆ
    # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: ãƒªã‚¯ã‚¨ã‚¹ãƒˆ > ç’°å¢ƒå¤‰æ•° > ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    work_dir = req.working_directory or os.getenv("MOCO_WORKING_DIRECTORY") or os.getcwd()
    orchestrator = Orchestrator(
        profile=req.profile,
        provider=req.provider,
        model=req.model,  # OpenRouterç”¨ãƒ¢ãƒ‡ãƒ«å
        session_logger=session_logger,
        verbose=req.verbose,
        progress_callback=progress_callback,
        working_directory=work_dir
    )

    session_id = req.session_id
    if not session_id:
        session_id = orchestrator.create_session(title=req.message[:50])

    # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç¢ºå®Ÿã«ã‚¯ãƒªã‚¢ã—ã¦ã‹ã‚‰æ–°è¦ç™»éŒ²
    # (éå»ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ã‚­ãƒ£ãƒ³ã‚»ãƒ«çŠ¶æ…‹ãŒæ®‹ã£ã¦ã„ã‚‹ã®ã‚’é˜²ã)
    clear_cancel_event(session_id)
    create_cancel_event(session_id)

    # çµæœã‚’æ ¼ç´ã™ã‚‹å¤‰æ•°
    result_holder = {"response": None, "error": None, "cancelled": False}
    stop_event = threading.Event()

    def run_orchestrator():
        try:
            result_holder["response"] = orchestrator.run_sync(req.message, session_id=session_id)
            # å®Œäº†ç›´å‰ã«å¼·åˆ¶ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
            progress_callback(event_type="flush")
        except OperationCancelled:
            result_holder["cancelled"] = True
            # ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ™‚ã¯ç‰¹åˆ¥ãªã‚¤ãƒ™ãƒ³ãƒˆã‚’æŠ•ã’ã‚‹
            event_queue.put({"type": "cancelled", "message": "Task was cancelled by user."})
        except Exception as e:
            result_holder["error"] = str(e)
        finally:
            # clear_cancel_event ã¯ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å´ã® check_cancelled å†…ã§ã‚‚å‘¼ã°ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€
            # ä¸‡ãŒä¸€ã®æ¼ã‚Œã‚’é˜²ããŸã‚ã“ã“ã§ã‚‚å‘¼ã¶ã€‚ãŸã ã—äºŒé‡å‘¼ã³å‡ºã—ã¯å•é¡Œãªã„è¨­è¨ˆã€‚
            clear_cancel_event(session_id)
            if not stop_event.is_set():
                event_queue.put({"type": "done"})

    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§å®Ÿè¡Œ
    thread = threading.Thread(target=run_orchestrator, daemon=True)
    thread.start()

    async def generate():
        # é–‹å§‹ã‚¤ãƒ™ãƒ³ãƒˆ
        yield f"data: {json.dumps({'type': 'start', 'session_id': session_id})}\n\n"
        await asyncio.sleep(0.01)

        has_sent_chunks = False

        try:
            while True:
                try:
                    # ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ã§ã‚­ãƒ¥ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
                    event = event_queue.get(timeout=0.1)

                    if event["type"] == "done":
                        # å®Œäº† - ãƒãƒ£ãƒ³ã‚¯ãŒä¸€åº¦ã‚‚é€ã‚‰ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ã€æœ€çµ‚çµæœã‚’é€ä¿¡
                        if result_holder["cancelled"]:
                            # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯åˆ¥é€”é€ä¿¡æ¸ˆã¿ï¼ˆtype: cancelledï¼‰ã ãŒã€
                            # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã®å‡¦ç†ç¢ºå®ŸåŒ–ã®ãŸã‚ã« status: cancelled ã‚‚é€ã‚‹
                            yield f"data: {json.dumps({'type': 'status', 'status': 'cancelled', 'content': 'Operation cancelled.'})}\n\n"
                        elif result_holder["error"]:
                            yield f"data: {json.dumps({'type': 'error', 'message': result_holder['error']})}\n\n"
                        elif not has_sent_chunks:
                            response = result_holder["response"] or ""
                            # verbose ã§ãªã„å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                            response = filter_response_for_display(response, req.verbose)
                            # çµæœã‚’ãƒãƒ£ãƒ³ã‚¯ã§é€ä¿¡
                            chunk_size = 100
                            for i in range(0, len(response), chunk_size):
                                chunk = response[i:i+chunk_size]
                                yield f"data: {json.dumps({'type': 'chunk', 'content': chunk})}\n\n"
                                await asyncio.sleep(0.01)

                        yield f"data: {json.dumps({'type': 'done'})}\n\n"
                        break
                    elif event["type"] == "chunk":
                        has_sent_chunks = True
                        yield f"data: {json.dumps(event)}\n\n"
                        await asyncio.sleep(0.01)
                    else:
                        # é€²æ—ã‚¤ãƒ™ãƒ³ãƒˆ
                        yield f"data: {json.dumps(event)}\n\n"
                        await asyncio.sleep(0.01)

                except queue.Empty:
                    # ã‚­ãƒ¥ãƒ¼ãŒç©º - å°‘ã—å¾…ã¤
                    await asyncio.sleep(0.05)
        finally:
            stop_event.set()

    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # Nginxãªã©ã®ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã‚’ç„¡åŠ¹åŒ–
        }
    )

@app.post("/api/debug/parse-json")
async def debug_parse_json(req: dict):
    """
    æ±šã‚ŒãŸ JSON æ–‡å­—åˆ—ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    """
    text = req.get("text", "")
    result = SmartJSONParser.parse(text)
    if result is None:
        raise HTTPException(status_code=400, detail="Failed to parse JSON")
    return {"result": result}


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
