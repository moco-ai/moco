import subprocess
import os
import re
import difflib
from typing import Tuple, Final
try:
    from ..utils.path import resolve_safe_path, get_working_directory
    from ..core.token_cache import TokenCache
except ImportError:
    # ã‚µãƒ–ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    from moco.utils.path import resolve_safe_path, get_working_directory
    from moco.core.token_cache import TokenCache

# å®‰å…¨æ€§ã®ãŸã‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ€å¤§è¡Œæ•° (read_file)
DEFAULT_MAX_LINES = 10000

# ç·¨é›†å¯èƒ½ãªæœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º (5MB)
MAX_EDIT_SIZE = 5 * 1024 * 1024

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_TOKEN_CACHE = TokenCache()

# å±é™ºãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©
DANGEROUS_PATTERNS: Final[list[str]] = [
    # ç ´å£Šçš„ãªå‰Šé™¤ (ãƒ•ãƒ©ã‚°ã«ä»»æ„ã®æ–‡å­—ã‚’å«ã‚ã‚‹ã‚ˆã†ã«æ”¹å–„)
    r'rm\s+.*(-[a-z]*[rf][a-z]*|--recursive|--force)\s+(/|~|\$HOME)',
    # ãƒ•ã‚©ãƒ¼ã‚¯ãƒœãƒ 
    r':\(\)\{\s*:\|:&\s*\};:',
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ»ãƒ‡ã‚£ã‚¹ã‚¯æ“ä½œ (ddã‚’ã‚ˆã‚Šå³ã—ã)
    r'mkfs\.',
    r'dd\s+.*of=',
    # ãƒ‡ãƒã‚¤ã‚¹ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ç›´æ¥æ›¸ãè¾¼ã¿/åˆ‡ã‚Šè©°ã‚ ( /dev/null ã¸ã®å‡ºåŠ›ã¯è¨±å¯ )
    r'(?<![0-9&])>\s*[^&|]',
    r'(?<!&)[0-9]>\s*[^&|]',
    # å…¨é–‹æ”¾ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³ãƒ»æ‰€æœ‰æ¨©
    r'chmod\s+.*777',
    r'chown\s+.*-R',
    # ã‚·ã‚§ãƒ«/ã‚¤ãƒ³ã‚¿ãƒ—ãƒªã‚¿ã¸ã®æµã—è¾¼ã¿
    r'[|;&<]\s*(bash|sh|zsh|python\d?|perl|ruby|php|node)\b',
    r'\b(bash|sh|zsh|python\d?|perl|ruby|php|node)\s+.*-c\s+',
    # ãƒªãƒ¢ãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ (ãƒ‘ã‚¤ãƒ—å…ˆã‚’æ‹¡å……)
    r'(curl|wget).*([|;&<]\s*(bash|sh|zsh|python\d?|perl|ruby|node)\b|-o\s+)',
    # ç‰¹æ¨©ä½¿ç”¨
    r'sudo\s+(rm|dd|chmod|chown|mkfs|su|apt|yum|dnf)\b',
    # findã«ã‚ˆã‚‹å‰Šé™¤
    r'find\s+.*\s+-delete',
]

# äº‹å‰ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„
_DANGEROUS_RE = re.compile('|'.join(f'(?:{p})' for p in DANGEROUS_PATTERNS), re.IGNORECASE)


def _find_similar_files(path: str, max_results: int = 3) -> list:
    """é¡ä¼¼ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ¤œç´¢"""
    try:
        abs_path = resolve_safe_path(path)
        parent_dir = os.path.dirname(abs_path)
        filename = os.path.basename(abs_path)
        
        if not os.path.exists(parent_dir):
            # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚å­˜åœ¨ã—ãªã„å ´åˆã€ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰æ¤œç´¢
            parent_dir = get_working_directory() or os.getcwd()
        
        if not os.path.isdir(parent_dir):
            return []
        
        # åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        try:
            files = os.listdir(parent_dir)
        except PermissionError:
            return []
        
        # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
        similar = difflib.get_close_matches(filename, files, n=max_results, cutoff=0.4)
        return [os.path.join(os.path.basename(parent_dir), f) for f in similar]
    except Exception:
        return []


def is_dangerous_command(command: str) -> Tuple[bool, str]:
    """ã‚³ãƒãƒ³ãƒ‰ãŒå±é™ºã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯"""
    # /dev/null ã¸ã®ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã‚’ä¸€æ™‚çš„ã«ç„¡å®³åŒ–ï¼ˆåˆ¤å®šã‹ã‚‰é™¤å¤–ï¼‰
    # ã‚¹ãƒšãƒ¼ã‚¹ã®æœ‰ç„¡ã«ã‹ã‹ã‚ã‚‰ãšå¯¾å¿œ
    safe_command = re.sub(r'[0-9&]?\s*>\s*/dev/null', '', command, flags=re.IGNORECASE)

    normalized_command = safe_command.strip()
    match = _DANGEROUS_RE.search(normalized_command)
    if match:
        return True, "Potentially destructive or unauthorized command detected."
    return False, ""


def read_file(path: str, offset: int = None, limit: int = None) -> str:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚“ã§è¿”ã—ã¾ã™ã€‚
    å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ offset ã¨ limit ã‚’æŒ‡å®šã—ã¦ä¸€éƒ¨ã ã‘èª­ã‚€ã“ã¨ã‚’æ¨å¥¨ã€‚

    Args:
        path (str): èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        offset (int, optional): èª­ã¿è¾¼ã¿é–‹å§‹è¡Œç•ªå·ï¼ˆ1å§‹ã¾ã‚Šï¼‰ã€‚çœç•¥æ™‚ã¯1è¡Œç›®ã‹ã‚‰ã€‚
        limit (int, optional): èª­ã¿è¾¼ã‚€è¡Œæ•°ã€‚çœç•¥æ™‚ã¯å…¨è¡Œï¼ˆãŸã ã— DEFAULT_MAX_LINES ã¾ã§ã®åˆ¶é™ã‚ã‚Šï¼‰ã€‚

    Returns:
        str: ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ï¼ˆè¡Œç•ªå·ä»˜ãï¼‰

    Examples:
        read_file("src/main.py")                    # å…¨ä½“ã‚’èª­ã‚€
        read_file("src/main.py", offset=100, limit=50)  # 100è¡Œç›®ã‹ã‚‰50è¡Œ
        read_file("package.json")                   # JSONè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
    
    Tips:
        - å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã¯ offset/limit ã§åˆ†å‰²ã—ã¦èª­ã‚€
        - ãƒã‚¤ãƒŠãƒªãƒ•ã‚¡ã‚¤ãƒ«ã¯èª­ã‚ãªã„ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®ã¿ï¼‰
    """
    try:
        # ãƒ‘ã‚¹ã‚’è§£æ±º
        abs_path = resolve_safe_path(path)
        if not os.path.exists(abs_path):
            msg = f"Error: File not found: {path}\n"
            similar = _find_similar_files(path)
            if similar:
                msg += "\nğŸ’¡ Did you mean:\n"
                for s in similar:
                    msg += f"  - {s}\n"
            parent = os.path.dirname(path) or "."
            msg += f"\nğŸ”„ Try: list_dir('{parent}') or glob_search('**/{os.path.basename(path)}')"
            return msg

        # LLM ã‹ã‚‰ã®å…¥åŠ›ã‚’å®‰å…¨ã«ã‚­ãƒ£ã‚¹ãƒˆ
        try:
            start_line = max(1, int(offset)) if offset is not None else 1
            max_lines = int(limit) if limit is not None else DEFAULT_MAX_LINES
        except (ValueError, TypeError):
            return "Error: Invalid offset or limit. They must be integers."

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ãƒã‚§ãƒƒã‚¯ (å…¨æ–‡èª­ã¿å–ã‚Šæ™‚ã®ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã‚’åˆ©ç”¨/ä¿å­˜ã™ã‚‹)
        # NOTE: limit ãŒæ–‡å­—åˆ—ã§æ¸¡ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€æ¯”è¼ƒã¯ int ã«ã‚­ãƒ£ã‚¹ãƒˆæ¸ˆã¿ã® max_lines ã‚’ä½¿ã†
        is_full_read = (start_line == 1 and (limit is None or max_lines >= DEFAULT_MAX_LINES))
        
        raw_content = None
        if is_full_read:
            raw_content = _TOKEN_CACHE.get(abs_path)

        if raw_content is None:
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
            try:
                with open(abs_path, 'r', encoding='utf-8', errors='replace') as f:
                    raw_content = f.read()
                # å…¨æ–‡èª­ã¿å–ã‚Šæ™‚ã®ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                if is_full_read:
                    _TOKEN_CACHE.set(abs_path, raw_content)
            except Exception as e:
                return f"Error reading file: {e}"

        # ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŒ‡å®šç¯„å›²ã‚’æŠ½å‡ºã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        lines = raw_content.splitlines()
        total_lines = len(lines)
        
        result_lines = []
        if start_line > 1:
            result_lines.append(f"... {start_line - 1} lines not shown ...")

        # æŠ½å‡ºç¯„å›²
        end_idx = min(start_line - 1 + max_lines, total_lines)
        for i in range(start_line - 1, end_idx):
            line_num = i + 1
            result_lines.append(f"{line_num:6}|{lines[i]}")

        if end_idx < total_lines:
            result_lines.append(f"... more lines available (limit={max_lines}, total={total_lines}) ...")
            
        return "\n".join(result_lines)

    except Exception as e:
        return f"Error processing file: {e}"


def write_file(path: str, content: str, overwrite: bool = False) -> str:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã«å†…å®¹ã‚’æ›¸ãè¾¼ã¿ã¾ã™ã€‚æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹ã‹ã€æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãã—ã¾ã™ã€‚

    Args:
        path (str): æ›¸ãè¾¼ã¿å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆç›¸å¯¾ãƒ‘ã‚¹ã¾ãŸã¯çµ¶å¯¾ãƒ‘ã‚¹ï¼‰
        content (str): ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€å†…å®¹ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ï¼‰
        overwrite (bool, optional): Trueã®å ´åˆã€æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Falseã€‚

    Returns:
        str: æˆåŠŸæ™‚ã¯æ›¸ãè¾¼ã‚“ã è¡Œæ•°ã€å¤±æ•—æ™‚ã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

    IMPORTANTï¼ˆå¿…ãšå®ˆã‚‹ï¼‰:
        - å¿…é ˆ: `path` ã¨ `content` ã‚’å¿…ãšæ¸¡ã™ï¼ˆç‰‡æ–¹ã§ã‚‚æ¬ ã‘ã‚‹ã¨å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ï¼‰
        - å¼•æ•°ã¯ã€ŒJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ1ã¤ã€ã§æ¸¡ã™ï¼ˆé€”ä¸­ã§åˆ‡ã‚ŒãŸ `{` ã‚„è¤‡æ•°JSONã¯NGï¼‰
        - æ”¹è¡Œã¯ `\\n`ã€ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã¯ `\\"` ã«å¿…ãšã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã™ã‚‹

    IMPORTANT - JSON arguments format:
        {
            "path": "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
            "content": "ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ï¼ˆæ”¹è¡Œã¯\\nã§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ï¼‰",
            "overwrite": false
        }

    Example JSON calls:
        {"path": "hello.txt", "content": "Hello World!"}
        {"path": "script.py", "content": "def main():\\n    print('hello')\\n"}
        {"path": "config.yaml", "content": "name: test\\nversion: 1.0\\n", "overwrite": true}

    æ³¨æ„:
        - contentå†…ã®æ”¹è¡Œã¯å¿…ãš \\n ã§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã™ã‚‹ã“ã¨
        - contentå†…ã®ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã¯ \\" ã§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã™ã‚‹ã“ã¨
        - å…¨ã¦ã®ã‚­ãƒ¼ã¨æ–‡å­—åˆ—å€¤ã¯ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã§å›²ã‚€ã“ã¨
    """
    try:
        # ãƒ‘ã‚¹ã‚’è§£æ±º
        abs_path = resolve_safe_path(path)

        # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‘ãƒƒãƒUIã®å‘¼ã³å‡ºã—
        if os.environ.get('MOCO_INTERACTIVE_PATCH') == '1':
            from ..ui.patch_viewer import preview_patch, save_patch
            old_content = ""
            if os.path.exists(abs_path):
                with open(abs_path, 'r', encoding='utf-8') as f:
                    old_content = f.read()

            choice = preview_patch(path, old_content, content, title=f"Write File: {path}")
            if choice == 'n':
                return "Write cancelled by user."
            if choice == 's':
                save_patch(path, old_content, content)
                return f"Patch saved for {path}. Write cancelled."
            if choice == 'e':
                return "Edit mode not implemented yet, write cancelled."

        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¬ãƒ¼ãƒ‰
        if os.path.exists(abs_path):
            try:
                with open(abs_path, 'r', encoding='utf-8', errors='replace') as f:
                    existing_lines = sum(1 for _ in f)
            except Exception:
                existing_lines = 0

            # new_lines = content.count('\n') + 1

            # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒ5è¡Œä»¥ä¸Šã®å ´åˆã¯ã€æ„å›³ã—ãªã„å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿æ¶ˆå¤±ã‚’é˜²ããŸã‚
            # write_file ã«ã‚ˆã‚‹å…¨ä¸Šæ›¸ãã‚’åˆ¶é™ã—ã€edit_file ã‚’æ¨å¥¨ã™ã‚‹ã€‚
            if existing_lines >= 5:
                # è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚overwrite=True ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¦ã‚‚æ‹’å¦ã™ã‚‹ã€‚
                return (
                    f"Error: Substantial existing content detected ({existing_lines} lines).\n"
                    "Overwriting large files with write_file is prohibited to prevent accidental data loss.\n"
                    "Please use edit_file(path, old_string, new_string) for partial modifications."
                )

            if not overwrite:
                file_size = os.path.getsize(abs_path)
                return (
                    f"Error: File already exists: {path} ({file_size} bytes)\n"
                    "To overwrite (only for small files < 5 lines), use: overwrite=True"
                )

        if os.path.dirname(abs_path):
            os.makedirs(os.path.dirname(abs_path), exist_ok=True)

        with open(abs_path, 'w', encoding='utf-8') as f:
            f.write(content)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–
        _TOKEN_CACHE.delete_by_path(abs_path)

        lines = content.count('\n') + 1
        ext = os.path.splitext(path)[1].lower()
        msg = f"âœ… Successfully wrote {lines} lines to {path}"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥ã«å¿œã˜ãŸæ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ
        if ext == '.py':
            msg += f"\n\nğŸ’¡ Next: execute_bash('python {path}') to test"
        elif ext in ('.js', '.ts'):
            msg += f"\n\nğŸ’¡ Next: execute_bash('node {path}') to test"
        elif ext == '.sh':
            msg += f"\n\nğŸ’¡ Next: execute_bash('bash {path}') to run"
        
        return msg
    except Exception as e:
        return f"Error writing file: {e}"


def edit_file(path: str, old_string: str, new_string: str, dry_run: bool = False) -> str:
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€éƒ¨ã‚’ç½®æ›ã—ã¦ç·¨é›†ã—ã¾ã™ï¼ˆsearch/replaceå½¢å¼ï¼‰ã€‚
    æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®šã®æ–‡å­—åˆ—ã‚’æ–°ã—ã„æ–‡å­—åˆ—ã«ç½®ãæ›ãˆã¾ã™ã€‚

    Args:
        path (str): ç·¨é›†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        old_string (str): ç½®æ›å¯¾è±¡ã®æ–‡å­—åˆ—ï¼ˆçŸ­ããƒ¦ãƒ‹ãƒ¼ã‚¯ãªéƒ¨åˆ†ã‚’æŒ‡å®šï¼‰
        new_string (str): ç½®æ›å¾Œã®æ–‡å­—åˆ—
        dry_run (bool, optional): Trueã®å ´åˆã€å®Ÿéš›ã«æ›¸ãè¾¼ã¾ãšã«å·®åˆ†ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚

    Returns:
        str: å®Ÿè¡Œçµæœãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¾ãŸã¯å·®åˆ†

    ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ï¼ˆé‡è¦ï¼‰:
        - old_string ã¯çŸ­ããƒ¦ãƒ‹ãƒ¼ã‚¯ãªéƒ¨åˆ†ã ã‘ã‚’æŒ‡å®šã™ã‚‹ï¼ˆ5-10è¡Œç¨‹åº¦ãŒç†æƒ³ï¼‰
        - å·¨å¤§ãª old_string ã¯ä¸€è‡´ã—ã«ãã„ï¼ˆã‚¨ã‚¹ã‚±ãƒ¼ãƒ—æ–‡å­—ã‚„ç©ºç™½ã®é•ã„ã§å¤±æ•—ã™ã‚‹ï¼‰
        - JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€å¤‰æ›´ã—ãŸã„ã‚­ãƒ¼ã®å‰å¾Œæ•°è¡Œã ã‘ã‚’æŒ‡å®šã™ã‚‹
        - å¤±æ•—ã—ãŸå ´åˆã¯ read_file ã§å®Ÿéš›ã®å†…å®¹ã‚’ç¢ºèªã—ã€ã‚ˆã‚ŠçŸ­ã„ old_string ã§å†è©¦è¡Œã™ã‚‹
    """
    try:
        abs_path = resolve_safe_path(path)
        if not os.path.exists(abs_path):
            msg = f"Error: File not found: {path}\n"
            similar = _find_similar_files(path)
            if similar:
                msg += "\nğŸ’¡ Did you mean:\n"
                for s in similar:
                    msg += f"  - {s}\n"
            msg += f"\nğŸ”„ Try: list_dir('{os.path.dirname(path) or '.'}') to find the correct file."
            return msg

        file_size = os.path.getsize(abs_path)
        if file_size > MAX_EDIT_SIZE:
             return f"Error: File too large ({file_size} bytes). Max {MAX_EDIT_SIZE} bytes."

        with open(abs_path, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()

        # æ”¹è¡Œã‚³ãƒ¼ãƒ‰ã®æºã‚‰ãã‚’å¸å
        content_unix = content.replace('\r\n', '\n')
        old_unix = old_string.replace('\r\n', '\n')
        new_unix = new_string.replace('\r\n', '\n')

        new_content = None

        # 1. å®Œå…¨ä¸€è‡´ (Strict Match)
        if content.count(old_string) == 1:
            new_content = content.replace(old_string, new_string, 1)
        elif content_unix.count(old_unix) == 1:
            new_content = content_unix.replace(old_unix, new_unix, 1)

        if new_content is None:
            # 2. ã‚¹ãƒãƒ¼ãƒˆãƒãƒƒãƒ (Indentation/Whitespace Insensitive Match)
            content_lines = content_unix.splitlines(keepends=True)
            old_lines = old_unix.splitlines()

            def normalize(s):
                return "".join(s.split())

            old_valid_indices = [i for i, line in enumerate(old_lines) if line.strip()]
            old_norm_lines = [normalize(old_lines[i]) for i in old_valid_indices]

            if not old_norm_lines:
                return "Error: old_string consists only of whitespace/empty lines."

            match_indices = []
            first_line_norm = old_norm_lines[0]

            for i, line in enumerate(content_lines):
                if normalize(line) == first_line_norm:
                    is_match = True
                    match_end_idx = i
                    old_idx_ptr = 1
                    offset = 1
                    while old_idx_ptr < len(old_norm_lines):
                        if i + offset >= len(content_lines):
                            is_match = False
                            break

                        target_line = content_lines[i + offset]
                        target_norm = normalize(target_line)
                        if target_norm == "":
                            offset += 1
                            continue

                        if target_norm == old_norm_lines[old_idx_ptr]:
                            old_idx_ptr += 1
                            match_end_idx = i + offset
                        else:
                            is_match = False
                            break
                        offset += 1

                    if is_match:
                        match_indices.append((i, match_end_idx + 1))

            if len(match_indices) == 0:
                msg = f"Error: old_string not found in {path}\n"
                
                # éƒ¨åˆ†ä¸€è‡´ã‚’æ¢ã™ï¼ˆæœ€åˆã®éç©ºè¡Œã§æ¤œç´¢ï¼‰
                first_old_line = next((l.strip() for l in old_lines if l.strip()), "")
                if first_old_line and len(first_old_line) > 10:
                    partial_matches = []
                    for i, line in enumerate(content_lines):
                        # æœ€åˆã®20æ–‡å­—ã§éƒ¨åˆ†ä¸€è‡´ã‚’æ¢ã™
                        if first_old_line[:20] in line or line.strip()[:20] in first_old_line:
                            partial_matches.append((i + 1, line.rstrip()[:80]))
                    
                    if partial_matches:
                        msg += f"\nğŸ“ Partial matches found (line numbers where similar content exists):\n"
                        for line_num, preview in partial_matches[:3]:
                            msg += f"  Line {line_num}: {preview}...\n"
                        msg += "\nTip: Use read_file to check exact content around these lines.\n"
                
                # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã®å·®ç•°ã‚’ãƒã‚§ãƒƒã‚¯
                normalized_old = set(normalize(ol) for ol in old_lines if ol.strip())
                normalized_content = {normalize(cl): cl for cl in content_lines if cl.strip()}
                
                matching_normalized = normalized_old & set(normalized_content.keys())
                if matching_normalized:
                    msg += f"\nâš ï¸ Content matches but formatting differs.\n"
                    sample = list(matching_normalized)[0]
                    actual_line = normalized_content[sample]
                    msg += f"Expected (normalized): {sample[:60]}...\n"
                    msg += f"Actual in file: {actual_line.rstrip()[:60]}...\n"
                    msg += "Tip: Check whitespace, indentation, or escape sequences.\n"
                
                # JSON ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯æ§‹é€ ã‚’è¡¨ç¤º
                if path.endswith('.json'):
                    msg += f"\nğŸ“‹ For JSON files, consider reading the file first to get exact content.\n"
                    # æœ€åˆã®10è¡Œã‚’è¡¨ç¤º
                    msg += f"File preview (first 10 lines):\n"
                    for i, line in enumerate(content_lines[:10]):
                        msg += f"  {i+1}: {line.rstrip()[:70]}\n"
                
                # old_string ãŒé•·ã™ãã‚‹å ´åˆã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹
                old_line_count = len([l for l in old_lines if l.strip()])
                if old_line_count > 10:
                    msg += f"\nğŸ”§ old_string ãŒé•·ã™ãã¾ã™ï¼ˆ{old_line_count}è¡Œï¼‰ã€‚\n"
                    msg += "   â†’ å¤‰æ›´ã—ãŸã„éƒ¨åˆ†ã®å‰å¾Œ5è¡Œç¨‹åº¦ã«çµã£ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚\n"
                    msg += "   â†’ ç‰¹ã«JSONãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯ã€å¤‰æ›´ã™ã‚‹ã‚­ãƒ¼ã®å‘¨è¾ºã ã‘ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\n"
                
                return msg

            if len(match_indices) > 1:
                msg = f"Error: Multiple matches found ({len(match_indices)}).\n"
                msg += "\nğŸ“ Matches at:\n"
                for start, end in match_indices[:5]:
                    preview = content_lines[start].strip()[:60]
                    msg += f"  Line {start+1}: {preview}...\n"
                msg += "\nğŸ’¡ Include more surrounding context in old_string to make it unique."
                return msg

            # ç½®æ›ã®å®Ÿè¡Œ
            start_line_idx, end_line_idx = match_indices[0]
            first_matched_line = content_lines[start_line_idx]
            original_indent = first_matched_line[:len(first_matched_line) - len(first_matched_line.lstrip())] if first_matched_line.strip() else ""

            new_lines_list = new_unix.splitlines()
            new_indents = [len(ln) - len(ln.lstrip()) for ln in new_lines_list if ln.strip()]
            min_new_indent = min(new_indents) if new_indents else 0

            replacement_lines = []
            for line in new_lines_list:
                if not line.strip():
                    replacement_lines.append("")
                    continue
                current_indent_len = len(line) - len(line.lstrip())
                relative_indent_len = max(0, current_indent_len - min_new_indent)
                indent_char = "\t" if "\t" in original_indent else " "
                indent_str = original_indent + (indent_char * relative_indent_len)
                replacement_lines.append(indent_str + line.lstrip())

            new_block = "\n".join(replacement_lines)
            if new_string.endswith('\n') or (end_line_idx < len(content_lines) and content_lines[end_line_idx-1].endswith('\n')):
                new_block += '\n'

            new_content = "".join(content_lines[:start_line_idx]) + new_block + "".join(content_lines[end_line_idx:])

        # 3. å·®åˆ†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (Dry Run)
        if dry_run:
            diff = difflib.unified_diff(
                content_unix.splitlines(),
                new_content.splitlines(),
                fromfile=f"a/{path}",
                tofile=f"b/{path}",
                lineterm=""
            )
            diff_text = "\n".join(diff)
            if not diff_text:
                return f"Simulation: No changes would be applied to {path} (content already matches)."
            return f"Simulation Results for {path}:\n\n{diff_text}\n\nTo apply these changes, call edit_file with dry_run=False."

        # 4. æ›¸ãè¾¼ã¿å®Ÿè¡Œ
        if os.environ.get('MOCO_INTERACTIVE_PATCH') == '1':
            try:
                from ..ui.patch_viewer import preview_patch, save_patch
                choice = preview_patch(path, content, new_content, title=f"Edit File: {path}")
                if choice == 'n':
                    return "Edit cancelled by user."
                if choice == 's':
                    save_patch(path, content, new_content)
                    return f"Patch saved for {path}. Edit cancelled."
            except ImportError:
                pass

        with open(abs_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

        _TOKEN_CACHE.delete_by_path(abs_path)
        
        # å¤‰æ›´è¡Œæ•°ã‚’è¨ˆç®—
        old_line_count = len(old_string.splitlines())
        new_line_count = len(new_string.splitlines())
        diff = new_line_count - old_line_count
        
        msg = f"âœ… Successfully edited {path}"
        if diff > 0:
            msg += f" (+{diff} lines)"
        elif diff < 0:
            msg += f" ({diff} lines)"
        
        return msg

    except Exception as e:
        import traceback
        return f"Error editing file: {e}\n{traceback.format_exc()}"


def execute_bash(command: str, allow_dangerous: bool = False) -> str:
    """
    Bashã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¿”ã—ã¾ã™ã€‚
    """
    try:
        # ã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹å®Ÿè¡Œã®åˆ¤å®š
        use_sandbox = os.environ.get("MOCO_SANDBOX") == "1"
        sandbox_image = os.environ.get("MOCO_SANDBOX_IMAGE", "python:3.12-slim")

        # å±é™ºãªã‚³ãƒãƒ³ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
        if not allow_dangerous and not use_sandbox:
            is_dangerous, reason = is_dangerous_command(command)
            if is_dangerous:
                return f"Error: Command blocked for security reasons. {reason}"

        # ãƒ‘ã‚¹ã‚’ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«è§£æ±º
        working_dir = get_working_directory()

        if use_sandbox:
            from .sandbox import execute_bash_in_sandbox
            return execute_bash_in_sandbox(
                command,
                image=sandbox_image,
                working_dir=working_dir,
                network_disabled=True,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§åˆ¶é™
                timeout=60
            )

        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­ã‘ã¦å®Ÿè¡Œ
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            timeout=60,
            cwd=working_dir  # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š
        )

        output = result.stdout
        if result.stderr:
            output += f"\nSTDERR:\n{result.stderr}"

        if result.returncode != 0:
            output += f"\nReturn Code: {result.returncode}"

        return output.strip() if output else "Command executed successfully (no output)."

    except subprocess.TimeoutExpired:
        return (
            "Error: Command execution timed out (60s).\n"
            "\nğŸ’¡ Suggestions:\n"
            "  - Use start_background() for long-running commands\n"
            "  - Add a timeout flag if the command supports it\n"
            "  - Break the task into smaller steps"
        )
    except Exception as e:
        return f"Error executing command: {e}"
